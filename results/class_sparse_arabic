(transformers) luffy:~/sparse-binary-transformers$ python3 main_ts_classification.py --config=configs/sparse_ts_classification_arabic.yaml --lr=1e-3
=> Reading YAML config from configs/sparse_ts_classification_arabic.yaml
Namespace(attention='Sparse', attention_prune_rate=0.5, batch_norm=True, batch_size=8, config='configs/sparse_ts_classification_arabic.yaml', conv_type=None, data='/s/luffy/b/nobackup/mgorb/data', dataset='SpokenArabicDigits', dmodel=128, entity=None, epochs=50, evaluate=False, freeze_weights=False, gpu=2, layer_norm=False, layer_norm_prune_rate=0.5, lin_prune_rate=0.5, log_dir=None, lr=0.001, mode='fan_in', model_type='Sparse', n_head=2, n_layers=2, name=None, nhid=256, nonlinearity='relu', num_classes=10, optimizer='sgd', pos_enc='Fixed', pretrained=None, print_freq=50, resume='', save_every=-1, save_graphs=False, save_scores=False, scale_fan=False, score_init=None, score_seed=0, seed=0, set='ImageNet', weight_file='sparse_cls_arabic', weight_init=None, weight_seed=0, window_size=None, workers=20)
2022-08-28 16:31:23.467841
2022-08-28 16:31:35.386650
2022-08-28 16:32:09.318634
2022-08-28 16:32:13.149428
(428935, 13)
5279 samples may be used for training
1320 samples will be used for validation
2199 samples will be used for testing
torch.Size([8, 65, 13])
(428935, 13)
(142935, 13)
Linear init
Using default weight initialization
Using default score initialization
Linear init
Using default weight initialization
Using default score initialization
Linear init
Using default weight initialization
Using default score initialization
Linear init
Using default weight initialization
Using default score initialization
Linear init
Using default weight initialization
Using default score initialization
Linear init
Using default weight initialization
Using default score initialization
Using default score initialization
Using default score initialization
Linear init
Using default weight initialization
Using default score initialization
Linear init
Using default weight initialization
Using default score initialization
=> Freezing model weights
==> No gradient to transformer_encoder.layers.0.self_attn.out_proj.weight
==> No gradient to transformer_encoder.layers.0.self_attn.out_proj.bias
==> No gradient to transformer_encoder.layers.0.self_attn.linear_Q.weight
==> No gradient to transformer_encoder.layers.0.self_attn.linear_Q.bias
==> No gradient to transformer_encoder.layers.0.self_attn.linear_K.weight
==> No gradient to transformer_encoder.layers.0.self_attn.linear_K.bias
==> No gradient to transformer_encoder.layers.0.self_attn.linear_V.weight
==> No gradient to transformer_encoder.layers.0.self_attn.linear_V.bias
==> No gradient to transformer_encoder.layers.0.linear1.weight
==> No gradient to transformer_encoder.layers.0.linear2.weight
==> No gradient to transformer_encoder.layers.1.self_attn.out_proj.weight
==> No gradient to transformer_encoder.layers.1.self_attn.out_proj.bias
==> No gradient to transformer_encoder.layers.1.self_attn.linear_Q.weight
==> No gradient to transformer_encoder.layers.1.self_attn.linear_Q.bias
==> No gradient to transformer_encoder.layers.1.self_attn.linear_K.weight
==> No gradient to transformer_encoder.layers.1.self_attn.linear_K.bias
==> No gradient to transformer_encoder.layers.1.self_attn.linear_V.weight
==> No gradient to transformer_encoder.layers.1.self_attn.linear_V.bias
==> No gradient to transformer_encoder.layers.1.linear1.weight
==> No gradient to transformer_encoder.layers.1.linear2.weight
==> No gradient to embedding.weight
==> No gradient to decoder.weight
The model has 366,720 trainable parameters
Train acc: 0.35627705628673234 | Val acc: 0.4462121212121212 | Test acc: 0.4309090909090909
Train acc: 0.4982413420171449 | Val acc: 0.6878787878787879 | Test acc: 0.6240909090909091
Train acc: 0.6104978355494413 | Val acc: 0.7545454545454545 | Test acc: 0.7059090909090909
Train acc: 0.664123376662081 | Val acc: 0.7840909090909091 | Test acc: 0.7666883117502385
Train acc: 0.7122564935322964 | Val acc: 0.8424242424242424 | Test acc: 0.8095454545454546
Train acc: 0.7552759741291856 | Val acc: 0.8727272727272727 | Test acc: 0.8595454545454545
Train acc: 0.8141504329262358 | Val acc: 0.8598484848484849 | Test acc: 0.8263636363636364
Train acc: 0.8465909090909091 | Val acc: 0.9128787878787878 | Test acc: 0.8977272727272727
Train acc: 0.872673160198963 | Val acc: 0.921969696969697 | Test acc: 0.9168181818181819
Train acc: 0.8835227272727273 | Val acc: 0.943939393939394 | Test acc: 0.9090909090909091
Train acc: 0.9 | Val acc: 0.9386363636363636 | Test acc: 0.9011688312617215
Train acc: 0.909280303030303 | Val acc: 0.9537878787878787 | Test acc: 0.95
Train acc: 0.9191017317049431 | Val acc: 0.9590909090909091 | Test acc: 0.9390909090909091
Train acc: 0.9253787878787879 | Val acc: 0.9590909090909091 | Test acc: 0.9313636363636364
Train acc: 0.9348484848484848 | Val acc: 0.9628787878787879 | Test acc: 0.9431818181818182
Train acc: 0.9335227272727272 | Val acc: 0.9742424242424242 | Test acc: 0.96
Train acc: 0.9407196969696969 | Val acc: 0.9659090909090909 | Test acc: 0.9390909090909091
Train acc: 0.9433441559473673 | Val acc: 0.9856060606060606 | Test acc: 0.9559090909090909
Train acc: 0.94464285716866 | Val acc: 0.978030303030303 | Test acc: 0.9513636363636364
Train acc: 0.9543290044322158 | Val acc: 0.9795454545454545 | Test acc: 0.9622727272727273
Train acc: 0.9556818181818182 | Val acc: 0.978030303030303 | Test acc: 0.9631818181818181
Train acc: 0.9526515151515151 | Val acc: 0.9825757575757575 | Test acc: 0.9563636363636364
Train acc: 0.9617153680685795 | Val acc: 0.9863636363636363 | Test acc: 0.9586363636363636
Train acc: 0.965719696969697 | Val acc: 0.975 | Test acc: 0.9577272727272728
Train acc: 0.9674242424242424 | Val acc: 0.9878787878787879 | Test acc: 0.9686363636363636
Train acc: 0.9660984848484848 | Val acc: 0.9901515151515151 | Test acc: 0.9627272727272728
Train acc: 0.9683441559473673 | Val acc: 0.9818181818181818 | Test acc: 0.9663636363636363
Train acc: 0.9691287878787879 | Val acc: 0.9916666666666667 | Test acc: 0.9668181818181818
Train acc: 0.9736742424242424 | Val acc: 0.9901515151515151 | Test acc: 0.9731818181818181
Train acc: 0.971780303030303 | Val acc: 0.9901515151515151 | Test acc: 0.9640909090909091
Train acc: 0.9725378787878788 | Val acc: 0.9840909090909091 | Test acc: 0.9577272727272728
Train acc: 0.9765151515151516 | Val acc: 0.9893939393939394 | Test acc: 0.9599350651827725
Train acc: 0.975189393939394 | Val acc: 0.9863636363636363 | Test acc: 0.9604545454545454
Train acc: 0.9765151515151516 | Val acc: 0.9893939393939394 | Test acc: 0.9636363636363636
Train acc: 0.9806818181818182 | Val acc: 0.9893939393939394 | Test acc: 0.97
Train acc: 0.9746212121212121 | Val acc: 0.9916666666666667 | Test acc: 0.9727272727272728
Train acc: 0.978219696969697 | Val acc: 0.9924242424242424 | Test acc: 0.9686363636363636
Train acc: 0.9806818181818182 | Val acc: 0.9893939393939394 | Test acc: 0.9640909090909091
Train acc: 0.9803030303030303 | Val acc: 0.9848484848484849 | Test acc: 0.9672727272727273
Train acc: 0.978760822614034 | Val acc: 0.9901515151515151 | Test acc: 0.9695454545454546
Train acc: 0.9823863636363637 | Val acc: 0.9893939393939394 | Test acc: 0.9636363636363636
Train acc: 0.9829545454545454 | Val acc: 0.9924242424242424 | Test acc: 0.9790909090909091